{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Analysis - Project 2\n",
    "\n",
    "**Ciaran Moran**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# receiving some user wraning messages, so i found this to prevent them being displayed\n",
    "# https://stackoverflow.com/questions/9134795/how-to-get-rid-of-specific-warning-messages-in-python-while-keeping-all-other-wa\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=Warning)\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_numeric(data):\n",
    "    data[['hpi']] = data[['hpi']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to strip white spaces from\n",
    "#### https://stackoverflow.com/questions/13385860/how-can-i-remove-extra-whitespace-from-strings-when-parsing-a-csv-file-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function took 10 mins 51 seconds to run!\n",
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below function from \n",
    "https://towardsdatascience.com/dealing-with-extra-white-spaces-while-reading-csv-in-pandas-67b0c2b71e6a\n",
    "#### and modified by me for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_strip(data, names, skiprows, encoding, skip_blank_lines, keep_default_na, na_filter, delim_whitespace, date_columns=[]):\n",
    "\n",
    "    #skiprows=6, encoding='unicode_escape',  skip_blank_lines=True, \n",
    "    # keep_default_na=True,na_filter=True)\n",
    "\n",
    "    # check if the names list has values or empty\n",
    "    if len(names):\n",
    "        df = pd.read_csv(data, names=names, skiprows=skiprows, encoding=encoding, \\\n",
    "                     skip_blank_lines=skip_blank_lines, keep_default_na=keep_default_na, \\\n",
    "                        na_filter=na_filter,quotechar='\"', delim_whitespace=delim_whitespace, parse_dates=date_columns)\n",
    "    else :\n",
    "            df = pd.read_csv(data, skiprows=skiprows, encoding=encoding, \\\n",
    "                     skip_blank_lines=skip_blank_lines, keep_default_na=keep_default_na, \\\n",
    "                        na_filter=na_filter,quotechar='\"', parse_dates=date_columns)\n",
    "\n",
    "    print('Before data clean')\n",
    "    print(data)\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    df = df.replace({\"\":np.nan}) # if there remained only empty string \"\", change to Nan\n",
    "\n",
    "    # for each column\n",
    "    for col in df.columns:\n",
    "        # check if the columns contains string data\n",
    "        #fi so strip whitespace\n",
    "        if pd.api.types.is_string_dtype(df[col]):\n",
    "            df[col] = df[col].str.strip()\n",
    "            #next we'll attempt to convert to numeric\n",
    "            #is not successful we'll continue as a string.\n",
    "            try:\n",
    "                #https://stackoverflow.com/questions/38553946/pandas-read-csv-convert-object-to-float\n",
    "                df[col] = df[col].apply(pd.to_numeric)\n",
    "            except Exception:\n",
    "                print ('>>>>>>>>>ERROR Converting :***',df[col], '*** from ', data,' <<<<<<<<<<<<<<<')\n",
    "                pass\n",
    "            #except AttributeError:\n",
    "            #    # process as a string\n",
    "            #    df[col] = df[col].str.strip()\n",
    "    df = df.replace({\"\":np.nan}) # if there remained only empty string \"\", change to Nan\n",
    "\n",
    "    print('AFTER data clean')\n",
    "    print(data)\n",
    "    print(df.dtypes)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the .csv files\n",
    "#### We can skip the first X rows in the csv as they are not pure data columns\n",
    "#### Initially received the error \"UnicodeDecodeError: 'utf-8' codec can't decode byte 0xfc in position 33: invalid start byte\"\n",
    "####\n",
    "#### Looking online I tried various suggestions from \n",
    "#### https://stackoverflow.com/questions/22216076/unicodedecodeerror-utf8-codec-cant-decode-byte-0xa5-in-position-0-invalid-s\n",
    "####\n",
    "#### The working solution appears to be encoding='unicode_escape'\n",
    "####\n",
    "#### The next issue was rows with all Nan values, which may cause issues later on.\n",
    "#### For this I tried keep_default_na=True,na_filter=True and also skip_blank_lines=True from \n",
    "#### https://stackoverflow.com/questions/39297878/how-to-skip-an-unknown-number-of-empty-lines-before-header-on-pandas-read-csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardisation\n",
    "\n",
    "##### File: 41586_2008_BFnature06949_MOESM31_ESM.csv\n",
    "\n",
    "Here I attempt to standardise the data.\n",
    "\n",
    "The initial issue is that we have 2 sets of data side by side.\n",
    "\n",
    "So I extract the data for University of Berlin into a seperate dataframe.\n",
    "\n",
    "Then I extract the data for LGGE in Grenoble into its own dataframe.\n",
    "\n",
    "I then rename the column titles to match those of University of Berlin.\n",
    "\n",
    "Then the dataframes are concatinated together into one dataframe.\n",
    "\n",
    "The result is a .csv with the data listed in a more consistant order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data clean\n",
      "data/41586_2008_BFnature06949_MOESM31_ESM.csv\n",
      "Depth (m)            float64\n",
      "EDC3_gas_a (yr)      float64\n",
      "CO2 (ppmv)           float64\n",
      "sigma (ppmv)         float64\n",
      "Depth (m).1          float64\n",
      "EDC3_gas_a (yr).1    float64\n",
      "CO2 (ppmv).1         float64\n",
      "Unnamed: 7           float64\n",
      "dtype: object\n",
      "AFTER data clean\n",
      "data/41586_2008_BFnature06949_MOESM31_ESM.csv\n",
      "Depth (m)            float64\n",
      "EDC3_gas_a (yr)      float64\n",
      "CO2 (ppmv)           float64\n",
      "sigma (ppmv)         float64\n",
      "Depth (m).1          float64\n",
      "EDC3_gas_a (yr).1    float64\n",
      "CO2 (ppmv).1         float64\n",
      "Unnamed: 7           float64\n",
      "dtype: object\n",
      "--------------------------\n",
      "moesm31_2 - head and tail\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Here we read in 41586_2008_BFnature06949_MOESM31_ESM.csv\n",
    "#\n",
    "df=read_csv_strip('data/41586_2008_BFnature06949_MOESM31_ESM.csv', [], 6, 'unicode_escape', \\\n",
    "               True, True, True, False, date_columns=[])\n",
    "\n",
    "#df = pd.read_csv('data/41586_2008_BFnature06949_MOESM31_ESM.csv', \\\n",
    "#                  skiprows=6, encoding='unicode_escape',  skip_blank_lines=True, \\\n",
    "#                   keep_default_na=True,na_filter=True)\n",
    "\n",
    "####################\n",
    "# University of Bern\n",
    "####################\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "moesm31_1 = df.iloc[0:247, 0:4] # This will copy columns 0 to 3, for rows 0-246 \n",
    "#Now add in some constants to standardise the data frame\n",
    "moesm31_1['station'] = 'moesm31'\n",
    "moesm31_1['uni'] = 'University of Bern'\n",
    "\n",
    "# Insert new column in position\n",
    "moesm31_1.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "moesm31_1[\"Gasage (AICC2012, yr BP)\"] = np.nan\n",
    " \n",
    "#print('--------------------------')\n",
    "#print('moesm31_1 - head and tail')\n",
    "#print('--------------------------')\n",
    "#print(moesm31_1.head())\n",
    "#print(moesm31_1.tail())\n",
    "\n",
    "save_filename = 'data/generated/moesm31_1.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "moesm31_1.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(moesm31_1.tail())\n",
    "\n",
    "###################\n",
    "# LGGE in Grenoble\n",
    "###################\n",
    "moesm31_2 = df.iloc[0:47, 4:7] # This will give you all rows for columns 4 to 6\n",
    "\n",
    "#print(moesm31_2.head())\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "moesm31_2.rename(columns={'Depth (m).1': 'Depth (m)', 'EDC3_gas_a (yr).1': 'EDC3_gas_a (yr)', \\\n",
    "                   'CO2 (ppmv).1': 'CO2 (ppmv)' }, inplace=True)\n",
    "#print(moesm31_2.head())\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "moesm31_2['sigma (ppmv)'] = '' # this data isn't present\n",
    "moesm31_2['station'] = 'moesm31'\n",
    "moesm31_2['uni'] = 'LGGE in Grenoble'\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "moesm31_2.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "moesm31_2[\"Gasage (AICC2012, yr BP)\"] = np.nan\n",
    "\t\n",
    " \n",
    "print('--------------------------')\n",
    "print('moesm31_2 - head and tail')\n",
    "print('--------------------------')\n",
    "#print(moesm31_2.head())\n",
    "#print(moesm31_2.tail())\n",
    "\n",
    "save_filename = 'data/generated/moesm31_2.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "moesm31_2.to_csv(save_filename, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we concatinate both files into one standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can append (concat) both of the new .csv files  \n",
    "# Ref: https://www.usepandas.com/csv/append-csv-files\n",
    "moesm31_combined=pd.concat([moesm31_1, moesm31_2])\n",
    "# Now add in the source file name, may come in handy later on\n",
    "moesm31_combined['source file'] = '41586_2008_BFnature06949_MOESM31_ESM.csv'\n",
    "\n",
    "# write out to csv, may not be necessary, but handy for checking data\n",
    "save_filename = 'data/generated/moesm31_combined.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "moesm31_combined.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(moesm31_combined.head)\n",
    "#print(moesm31_combined.tail)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File data/grl52461-sup-0003-supplementary.csv\n",
    "\n",
    "#### Now we process the larger of the two files.\n",
    "#### I can re-use some of the code I created for the smaller file.\n",
    "#### Also the lessons learned and knowledge garnered for the smaller file will be invaluable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##  Read in supplementary file grl52461-sup-0003-supplementary.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data clean\n",
      "data/grl52461-sup-0003-supplementary.csv\n",
      "Depth (m)                                        float64\n",
      "Gasage (EDC3, yr BP)                             float64\n",
      "Gasage (AICC2012, yr BP)                         float64\n",
      "CO2 (ppmv)                                       float64\n",
      "sigma mean CO2 (ppmv)                            float64\n",
      "                                                  ...   \n",
      "analytical sigma mean CO2 (ppmv)                 float64\n",
      "Correcting Factor (ppmv)                         float64\n",
      "lower bound (2 sigma) of correction F. (ppmv)    float64\n",
      "upper bound (2 sigma) of correction F. (ppmv)    float64\n",
      "Unnamed: 108                                     float64\n",
      "Length: 109, dtype: object\n",
      "AFTER data clean\n",
      "data/grl52461-sup-0003-supplementary.csv\n",
      "Depth (m)                                        float64\n",
      "Gasage (EDC3, yr BP)                             float64\n",
      "Gasage (AICC2012, yr BP)                         float64\n",
      "CO2 (ppmv)                                       float64\n",
      "sigma mean CO2 (ppmv)                            float64\n",
      "                                                  ...   \n",
      "analytical sigma mean CO2 (ppmv)                 float64\n",
      "Correcting Factor (ppmv)                         float64\n",
      "lower bound (2 sigma) of correction F. (ppmv)    float64\n",
      "upper bound (2 sigma) of correction F. (ppmv)    float64\n",
      "Unnamed: 108                                     float64\n",
      "Length: 109, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here we read in grl52461-sup-0003-supplementary.csv\n",
    "#\n",
    "df=read_csv_strip('data/grl52461-sup-0003-supplementary.csv', [], 6, 'unicode_escape', \\\n",
    "               True, True, True, False, date_columns=[])\n",
    "\n",
    "#df = pd.read_csv('data/grl52461-sup-0003-supplementary.csv', \\\n",
    "#                 skiprows=6, encoding='unicode_escape',  skip_blank_lines=True, keep_default_na=True,na_filter=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "##  supplementary.csv - Dome C - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file grl52461-sup-0003-supplementary.csv...\n",
      "save_filename : data/generated/suppl_Dome C (0-22 kyr BP)P_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - University of Bern\n",
    "#########################################\n",
    "row_offset = -7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "print('Processing file grl52461-sup-0003-supplementary.csv...')\n",
    "\n",
    "station = 'Dome C (0-22 kyr BP)P'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_1 = df.iloc[0:183, 0:5].copy() # This will copy columns 0 to 3, for rows 0-246 \n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_1['station'] = station\n",
    "suppl_1['uni'] = uni\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "suppl_1.rename(columns={'Gasage (EDC3, yr BP)': 'EDC3_gas_a (yr)', \\\n",
    "                        'sigma mean CO2 (ppmv)': 'sigma (ppmv)', \\\n",
    "                   'CO2 (ppmv).1': 'CO2 (ppmv)' }, inplace=True)\n",
    "\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_1.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_1.head())\n",
    "#print(suppl_1.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - Vostok - LGGE Grenoble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Vostok (0-440 kyr BP)_LGGE Grenoble.csv\n",
      "Processing file grl52461-sup-0003-supplementary.csv...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################\n",
    "# supplementary.csv  - Vostok - LGGE Grenoble\n",
    "#########################################\n",
    "#\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Vostok (0-440 kyr BP)'\n",
    "uni = 'LGGE Grenoble'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "print('Processing file grl52461-sup-0003-supplementary.csv...')\n",
    "suppl_2 = df.iloc[0:372, 5:9].copy() \n",
    "\n",
    "#Depth (m).1\tGasage (EDC3, yr BP).1\tGasage (AICC2012, yr BP).1\tCO2 (ppmv).1\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "suppl_2.rename(columns={'Depth (m).1': 'Depth (m)', 'Gasage (EDC3, yr BP).1': 'Gasage (EDC3, yr BP)', \\\n",
    "                    'Gasage (AICC2012, yr BP).1': 'Gasage (AICC2012, yr BP)', \\\n",
    "                   'CO2 (ppmv).1': 'CO2 (ppmv)' }, inplace=True)\n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_2['sigma mean CO2 (ppmv)'] = '0' # add in missing column\n",
    "suppl_2['station'] = station\n",
    "suppl_2['uni'] = uni\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_2.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_2.head())\n",
    "#print(suppl_2.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - Taylor Dome - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Taylor Dome (19-63 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Taylor Dome - University of Bern\n",
    "#########################################\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Taylor Dome (19-63 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_3 = df.iloc[0:66-row_offset, 9:13].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# Depth (m).2\ttentatively synchronized on EDC3 gasage (yr)\tCO2 (ppmv).2\tsigma mean CO2 (ppmv).1\tstation\tuni\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "suppl_3.rename(columns={'Depth (m).2': 'Depth (m)', \\\n",
    "                        'tentatively synchronized on EDC3 gasage (yr)': 'Gasage (EDC3, yr BP)', \\\n",
    "                                           'CO2 (ppmv).2': 'CO2 (ppmv)' , \\\n",
    "                                            'sigma mean CO2 (ppmv).1': 'sigma mean CO2 (ppmv)' }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_3['station'] = station\n",
    "suppl_3['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "suppl_3.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "# https://sparkbyexamples.com/pandas/pandas-add-an-empty-column-to-dataframe/#:~:text=To%20add%20an%20empty%20column%20to%20an%20existing%20Pandas%20DataFrame,prefer%2C%20you%20can%20use%20np.\n",
    "suppl_3[\"Gasage (AICC2012, yr BP)\"] = np.nan\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_3.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_3.head())\n",
    "#print(suppl_3.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - Dome C (393-664 kyr BP) - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Dome C (393-664 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Dome C (393-664 kyr BP) - University of Bern\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Dome C (393-664 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_4 = df.iloc[0:329-row_offset, 13:18].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_4.rename(columns={'Depth (m).3': 'Depth (m)', \\\n",
    "                        'Gasage (AICC2012, yr BP).2': 'Gasage (AICC2012, yr BP)', \\\n",
    "                        'Gasage (EDC3, yr BP).2': 'Gasage (EDC3, yr BP)', \\\n",
    "                                           'CO2 (ppmv).3': 'CO2 (ppmv)' , \\\n",
    "                                            'sigma mean CO2 (ppmv).2': 'sigma mean CO2 (ppmv)' }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_4['station'] = station\n",
    "suppl_4['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_4.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_4.head())\n",
    "#print(suppl_4.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Dome C (393-664 kyr BP)_LGGE Grenoble.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Dome C (393-664 kyr BP) - LGGE Grenoble\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Dome C (393-664 kyr BP)'\n",
    "uni = 'LGGE Grenoble'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_5 = df.iloc[0:38-row_offset, 18:23].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#REQUIRED HEADINGS\n",
    "#Depth (m)\tGasage (EDC3, yr BP)\tGasage (AICC2012, yr BP)\tCO2 (ppmv)\tsigma mean CO2 (ppmv)\tstation\tuni\n",
    "\n",
    "\n",
    "suppl_5.rename(columns={'Depth (m).4': 'Depth (m)', \\\n",
    "                        'Gasage (EDC3, yr BP).3': 'Gasage (EDC3, yr BP)', \\\n",
    "                        'Gasage (AICC2012, yr BP).3': 'Gasage (AICC2012, yr BP)', \\\n",
    "                        'CO2 (ppmv).4': 'CO2 (ppmv)' , \\\n",
    "                        'sigma mean CO2 (ppmv).3': 'sigma mean CO2 (ppmv)' }, \\\n",
    "                        inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_5['station'] = station\n",
    "suppl_5['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_5.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_5.head())\n",
    "#print(suppl_5.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - Dome C (611-800 kyr BP) - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Dome C (611-800 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Dome C (611-800 kyr BP) - University of Bern\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Dome C (611-800 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_5 = df.iloc[0:258-row_offset, 22:27].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_5.rename(columns={'Depth (m).5': 'Depth (m)', \\\n",
    "                        'Gasage (EDC3, yr BP).4': 'Gasage (EDC3, yr BP)', \\\n",
    "                        'Gasage (AICC2012, yr BP).4': 'Gasage (AICC2012, yr BP)', \\\n",
    "                        'sigma mean CO2 (ppmv).3': 'sigma mean CO2 (ppmv)', \\\n",
    "                                           'CO2 (ppmv).5': 'CO2 (ppmv)' }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_5['station'] = station\n",
    "suppl_5['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_5.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_5.head())\n",
    "#print(suppl_5.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Dome C (611-800 kyr BP)_LGGE Grenoble.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Dome C (611-800 kyr BP) - LGGE Grenoble\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Dome C (611-800 kyr BP)'\n",
    "uni = 'LGGE Grenoble'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_6 = df.iloc[0:54-row_offset, 27:31].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).6\tGasage (EDC3, yr BP).5\tGasage (AICC2012, yr BP).5\tCO2 (ppmv).6\t\n",
    "\n",
    "suppl_6.rename(columns={'Depth (m).6': 'Depth (m)', \\\n",
    "                        'Gasage (EDC3, yr BP).5': 'Gasage (EDC3, yr BP)', \\\n",
    "                        'Gasage (AICC2012, yr BP).5': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).6': 'CO2 (ppmv)' }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_6['station'] = station\n",
    "suppl_6['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_6.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_6.head())\n",
    "#print(suppl_6.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - Talos Dome (35-68 kyr BP) - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Talos Dome (35-68 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Talos Dome (35-68 kyr BP) - University of Bern\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Talos Dome (35-68 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_7 = df.iloc[0:123-row_offset, 31:37].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_7.rename(columns={'Depth (m).7': 'Depth (m)', \\\n",
    "                        'Gasage (EDC3, yr BP).6': 'Gasage (EDC3, yr BP)', \\\n",
    "                        'Gasage (AICC2012, yr BP).6': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).7': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).4': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_7['station'] = station\n",
    "suppl_7['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_7.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_7.head())\n",
    "#print(suppl_7.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - EDML (49-115 kyr BP) - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_EDML (49-115 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - EDML (49-115 kyr BP) - University of Bern\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'EDML (49-115 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_8 = df.iloc[0:165-row_offset, 37:43].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_8.rename(columns={'Depth (m).8': 'Depth (m)', \\\n",
    "                        'Gasage (EDML1 Sz4, yr BP).1': 'Gasage (EDML1 Sz4, yr BP)', \\\n",
    "                        'Gasage (EDC3, yr BP).6': 'Gasage (EDC3, yr BP)', \\\n",
    "                        'Gasage (AICC2012, yr BP).7': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).8': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).5': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_8['station'] = station\n",
    "suppl_8['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_8.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_8.head())\n",
    "#print(suppl_8.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - Byrd (19-88 kyr BP) - Oregon State University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_Byrd (19-88 kyr BP)_Oregon State University.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - Byrd (19-88 kyr BP) - Oregon State University\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'Byrd (19-88 kyr BP)'\n",
    "uni = 'Oregon State University'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_9 = df.iloc[0:178-row_offset, 43:48].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_9.rename(columns={'Depth (m).9': 'Depth (m)', \\\n",
    "                        'tentatively synchronized on AICC2012 based on synchronization applied in Bereiter et al. (2012)': \\\n",
    "                            'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).9': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).6': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_9['station'] = station\n",
    "suppl_9['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_9.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_9.head())\n",
    "#print(suppl_9.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - EDC (9-22 kyr BP) - LGGE Grenoble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_EDC (9-22 kyr BP)_LGGE Grenoble.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - EDC (9-22 kyr BP) - LGGE Grenoble\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'EDC (9-22 kyr BP)'\n",
    "uni = 'LGGE Grenoble'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_10 = df.iloc[0:70-row_offset, 48:53].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_10.rename(columns={'Depth (m).10': 'Depth (m)', \\\n",
    "                         'Gasage (EDC3, yr BP).6': 'Gasage (EDC3, yr BP)', \\\n",
    "                         'Gasage (AICC2012, yr BP).8': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).10': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).7': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_10['station'] = station\n",
    "suppl_10['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_10.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_10.head())\n",
    "#print(suppl_10.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - EDC (125- 153 kyr BP) - LGGE Grenoble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_EDC (125- 153 kyr BP)_LGGE Grenoble.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv -  EDC (125- 153 kyr BP)- LGGE Grenoble\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'EDC (125- 153 kyr BP)'\n",
    "uni = 'LGGE Grenoble'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_11 = df.iloc[0:46-row_offset, 53:58].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_11.rename(columns={'Depth (m).11': 'Depth (m)', \\\n",
    "                         'Gasage (EDC3, yr BP).7': 'Gasage (EDC3, yr BP)', \\\n",
    "                         'Gasage (AICC2012, yr BP).9': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).11': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).8': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_11['station'] = station\n",
    "suppl_11['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_11.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_11.head())\n",
    "#print(suppl_11.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - EDC (12-24 kyr BP) - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_EDC (12-24 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv - EDC (12-24 kyr BP) - University of Bern\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'EDC (12-24 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_12 = df.iloc[0:32-row_offset, 58:63].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_12.rename(columns={'Depth (m).12': 'Depth (m)', \\\n",
    "                        'Gasage (EDC3, yr BP).8': 'Gasage (EDC3, yr BP)', \\\n",
    "                        'Gasage (AICC2012, yr BP).10': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).12': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).9': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_12['station'] = station\n",
    "suppl_12['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_12.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_12.head())\n",
    "#print(suppl_12.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## supplementary.csv - EDC (105-155 kyr BP) - University of Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_filename : data/generated/suppl_EDC (105-155 kyr BP)_University of Bern.csv\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# supplementary.csv -  EDC (105-155 kyr BP)- University of Bern\n",
    "#########################################\n",
    "\n",
    "row_offset = 7\n",
    "\n",
    "# Ref https://stackoverflow.com/questions/61553063/read-csv-file-by-column-number-in-pandas-python\n",
    "#\n",
    "station = 'EDC (105-155 kyr BP)'\n",
    "uni = 'University of Bern'\n",
    "save_filename = 'data/generated/suppl_' + station + '_' + uni + '.csv'\n",
    "print('save_filename :', save_filename)\n",
    "\n",
    "suppl_13 = df.iloc[0:77-row_offset, 63:68].copy() # This will copy columns from the main .csv file\n",
    "\n",
    "# https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "#Depth (m).3\tGasage (EDC3, yr BP).2\tGasage (AICC2012, yr BP)\tGasage (AICC2012, yr BP).2\tCO2 (ppmv).3\t\n",
    "# sigma mean CO2 (ppmv).2\tstation\tuni\n",
    "suppl_13.rename(columns={'Depth (m).13': 'Depth (m)', \\\n",
    "                         'Gasage (EDC3, yr BP).9': 'Gasage (EDC3, yr BP)', \\\n",
    "                         'Gasage (AICC2012, yr BP).11': 'Gasage (AICC2012, yr BP)', \\\n",
    "                                           'CO2 (ppmv).13': 'CO2 (ppmv)', \\\n",
    "                                            'sigma mean CO2 (ppmv).10': 'sigma mean CO2 (ppmv)' \\\n",
    "                                            }, \\\n",
    "                                            inplace=True) \n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "suppl_13['station'] = station\n",
    "suppl_13['uni'] = uni\n",
    "\n",
    "# Insert new column in position\n",
    "# https://discuss.codecademy.com/t/can-we-add-a-new-column-at-a-specific-position-in-a-pandas-dataframe/355842\n",
    "#suppl_4.insert(2,'Gasage (AICC2012, yr BP)',' ') # As this column exists in the supplementary file\n",
    "\t\t\n",
    "\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_13.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(suppl_13.head())\n",
    "#print(suppl_13.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we concatinate all the supplementary files into one standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can append (concat) all of the new .csv files  \n",
    "# Ref: https://www.usepandas.com/csv/append-csv-files\n",
    "suppl_combined=pd.concat([suppl_3,suppl_4,suppl_5,suppl_6,suppl_7,suppl_8,suppl_9,suppl_10,suppl_11,suppl_12,suppl_13])\n",
    "# Now add in the source file name, may come in handy later on\n",
    "suppl_combined['source file'] = 'grl52461-sup-0003-supplementary.csv'\n",
    "\n",
    "# write out to csv, may not be necessary, but handy for checking data\n",
    "save_filename = 'data/generated/suppl_combined.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "suppl_combined.to_csv(save_filename, index=False)\n",
    "#print(suppl_combined.head)\n",
    "#print(suppl_combined.tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process edc3deuttemp2007.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data clean\n",
      "data/edc3deuttemp2007.txt\n",
      "Bag              int64\n",
      "Depth (m)      float64\n",
      "Age            float64\n",
      "Deuterium      float64\n",
      "Temperature    float64\n",
      "dtype: object\n",
      "AFTER data clean\n",
      "data/edc3deuttemp2007.txt\n",
      "Bag              int64\n",
      "Depth (m)      float64\n",
      "Age            float64\n",
      "Deuterium      float64\n",
      "Temperature    float64\n",
      "dtype: object\n",
      "   Bag  Depth (m)       Age  Deuterium  Temperature       station        uni\n",
      "0    1       0.00 -50.00000        NaN          NaN  EPICA Dome C  NOAA/NCDC\n",
      "1    2       0.55 -43.54769        NaN          NaN  EPICA Dome C  NOAA/NCDC\n",
      "2    3       1.10 -37.41829        NaN          NaN  EPICA Dome C  NOAA/NCDC\n",
      "3    4       1.65 -31.61153        NaN          NaN  EPICA Dome C  NOAA/NCDC\n",
      "4    5       2.20 -24.51395        NaN          NaN  EPICA Dome C  NOAA/NCDC\n",
      "       Bag  Depth (m)       Age  Deuterium  Temperature       station  \\\n",
      "5795  5796    3187.25  797408.0    -440.20        -8.73  EPICA Dome C   \n",
      "5796  5797    3187.80  798443.0    -439.00        -8.54  EPICA Dome C   \n",
      "5797  5798    3188.35  799501.0    -441.10        -8.88  EPICA Dome C   \n",
      "5798  5799    3188.90  800589.0    -441.42        -8.92  EPICA Dome C   \n",
      "5799  5800    3189.45  801662.0    -440.90        -8.82  EPICA Dome C   \n",
      "\n",
      "            uni  \n",
      "5795  NOAA/NCDC  \n",
      "5796  NOAA/NCDC  \n",
      "5797  NOAA/NCDC  \n",
      "5798  NOAA/NCDC  \n",
      "5799  NOAA/NCDC  \n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "### Process edc3deuttemp2007.txt\n",
    "####################################\n",
    "\n",
    "# Refs\n",
    "# https://stackoverflow.com/questions/21546739/load-data-from-txt-with-pandas\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "#\n",
    "# Note,needed to add skipinitialspace=True \n",
    "# to get the read_csv to work.\n",
    "#\n",
    "edc3deuttemp2007=read_csv_strip('data/edc3deuttemp2007.txt', \\\n",
    "                ['Bag', 'Depth (m)', 'Age', 'Deuterium', 'Temperature'], 92, 'unicode_escape', \\\n",
    "               True, True, True, True,  date_columns=[])\n",
    "\n",
    "#edc3deuttemp2007 = pd.read_csv('data/edc3deuttemp2007.txt', sep=\" \", \\\n",
    "#                   skiprows=92,   \\\n",
    "#                   names=['Bag', 'Depth (m)', 'Age', 'Deuterium', 'Temperature'], \\\n",
    "#                    skip_blank_lines=True, skipinitialspace=True )\n",
    "#, encoding='unicode_escape',keep_default_na=True,na_filter=True)\n",
    "\n",
    "\n",
    "#Column 1: Bag number (55 cm sample)\n",
    "#Column 2: Top depth (m)\n",
    "#Column 3: EDC3 age scale (years before year 1950)\n",
    "#Column 4: dD data (per mille with respect to SMOW)\n",
    "#Column 5: Temperature estimate (temperature difference from the average of the last 1000 years)\n",
    "#Bag         ztop          Age         Deuterium    Temperature\n",
    "#Depth (m)\tEDC3_gas_a (yr)\tGasage (AICC2012, yr BP)\tCO2 (ppmv)\tsigma (ppmv)\tstation\tuni\tsource file\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "edc3deuttemp2007['station'] = 'EPICA Dome C'\n",
    "edc3deuttemp2007['uni'] = 'NOAA/NCDC'\n",
    "\n",
    "# write out to csv, may not be necessary, but handy for checking data\n",
    "save_filename = 'data/generated/edc3deuttemp2007.new.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "edc3deuttemp2007.to_csv(save_filename, index=False)\n",
    "\n",
    "print(edc3deuttemp2007.head())\n",
    "print(edc3deuttemp2007.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process epicaDC.deuttemp.EDC3-AICC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data clean\n",
      "data/edc3deuttemp2007.txt\n",
      "Bag                           int64\n",
      "Depth (m)                   float64\n",
      "EDC3_gas_a (yr)             float64\n",
      "Gasage (AICC2012, yr BP)    float64\n",
      "deutfinal                   float64\n",
      "temp                        float64\n",
      "acc-EDC3beta                float64\n",
      "dtype: object\n",
      "AFTER data clean\n",
      "data/edc3deuttemp2007.txt\n",
      "Bag                           int64\n",
      "Depth (m)                   float64\n",
      "EDC3_gas_a (yr)             float64\n",
      "Gasage (AICC2012, yr BP)    float64\n",
      "deutfinal                   float64\n",
      "temp                        float64\n",
      "acc-EDC3beta                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "### Process epicaDC.deuttemp.EDC3-AICC.csv\n",
    "####################################\n",
    "\n",
    "# Refs\n",
    "# https://stackoverflow.com/questions/21546739/load-data-from-txt-with-pandas\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "#\n",
    "# Note,needed to add skipinitialspace=True \n",
    "# to get the read_csv to work.\n",
    "#\n",
    "#Depth (m)\tEDC3_gas_a (yr)\tGasage (AICC2012, yr BP)\tCO2 (ppmv)\tsigma (ppmv)\tstation\tuni\tsource file\n",
    "#bag\tztop\tEDC3bta  \tAICC2012\t  deutfinal\t  temp\t  acc-EDC3beta\n",
    "epicaDCdeuttempEDC3AICC=read_csv_strip('data/edc3deuttemp2007.txt', \\\n",
    "                ['Bag', 'Depth (m)', 'EDC3_gas_a (yr)', 'Gasage (AICC2012, yr BP)', \\\n",
    "                 'deutfinal', 'temp', 'acc-EDC3beta'],\\\n",
    "                  92, 'unicode_escape', \\\n",
    "               True, True, True, True, date_columns=[])\n",
    "\n",
    "#epicaDCdeuttempEDC3AICC = pd.read_csv('data/epicaDC.deuttemp.EDC3-AICC.csv',  \\\n",
    "#                   skiprows=92,   \\\n",
    "#                   names=['Bag', 'Depth (m)', 'EDC3_gas_a (yr)', 'Gasage (AICC2012, yr BP)', \\\n",
    "#                          'deutfinal', 'temp', 'acc-EDC3beta'], \\\n",
    "#                   names=['bag', 'ztop', 'EDC3bta', 'AICC2012', 'deutfinal', 'temp', 'acc-EDC3beta'], \\\n",
    "#                    skip_blank_lines=True, skipinitialspace=True )\n",
    "#, encoding='unicode_escape',keep_default_na=True,na_filter=True)\n",
    "#                   names=['Bag', 'Depth (m)', 'EDC3_gas_a (yr)', 'Deuterium', 'Temperature'], \\\n",
    "\n",
    "epicaDCdeuttempEDC3AICC.rename(columns={'EDC3bta': 'EDC3_gas_a (yr)', \\\n",
    "                'ztop': 'Depth (m)', \\\n",
    "                   'CO2 (ppmv).1': 'CO2 (ppmv)' }, inplace=True)\n",
    "\n",
    "#Now add in some constants to standardise the data frame\n",
    "epicaDCdeuttempEDC3AICC['station'] = 'EPICA Dome C'\n",
    "epicaDCdeuttempEDC3AICC['uni'] = 'NOAA/NCDC'\n",
    "\n",
    "# write out to csv, may not be necessary, but handy for checking data\n",
    "save_filename = 'data/generated/epicaDC.deuttemp.EDC3-AICC.csv.new.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "epicaDCdeuttempEDC3AICC.to_csv(save_filename, index=False)\n",
    "\n",
    "#print(epicaDCdeuttempEDC3AICC.head())\n",
    "#print(epicaDCdeuttempEDC3AICC.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now finally combine all files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'data/generated/all_combined.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# write out to csv, may not be necessary, but handy for checking data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m save_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/generated/all_combined.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(save_filename): os\u001b[38;5;241m.\u001b[39mremove(save_filename) \u001b[38;5;66;03m# delete if exists\u001b[39;00m\n\u001b[0;32m     13\u001b[0m all_combined\u001b[38;5;241m.\u001b[39mto_csv(save_filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Now write out to JSON file\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ref https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ref https://stackoverflow.com/questions/29271520/valueerror-dataframe-index-must-be-unique-for-orient-columns\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'data/generated/all_combined.csv'"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Now finally combine all files into one\n",
    "##########################################\n",
    "\n",
    "all_combined=pd.concat([moesm31_combined,suppl_combined, edc3deuttemp2007, epicaDCdeuttempEDC3AICC])\n",
    "all_combined = all_combined.reset_index()\n",
    "# ref https://stackoverflow.com/questions/77478335/cleaning-dataframe-typeerror-not-supported-between-instances-of-str-and\n",
    "all_combined['Depth (m)'] = pd.to_numeric(all_combined['Depth (m)'], errors='coerce')\n",
    "\n",
    "# write out to csv, may not be necessary, but handy for checking data\n",
    "save_filename = 'data/generated/all_combined.csv'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "all_combined.to_csv(save_filename, index=False)\n",
    "\n",
    "# Now write out to JSON file\n",
    "# Ref https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html\n",
    "# Ref https://stackoverflow.com/questions/29271520/valueerror-dataframe-index-must-be-unique-for-orient-columns\n",
    "save_filename = 'data/generated/all_combined.json'\n",
    "if os.path.isfile(save_filename): os.remove(save_filename) # delete if exists\n",
    "all_combined.to_json(save_filename,orient=\"split\")\n",
    "\n",
    "#print(all_combined.head)\n",
    "#print(all_combined.tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Generate the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of the numerical variables, and then use in a loop.\n",
    "# ref https://seaborn.pydata.org/generated/seaborn.histplot.html\n",
    "print(all_combined.dtypes)\n",
    "#numeric_vars = ['(Depth m)', 'EDC3_gas_a (yr)', 'Gasage (AICC2012, yr BP)', 'CO2 (ppmv)', 'sigma (ppmv)']\n",
    "\n",
    "numeric_vars = ['Depth (m)', 'EDC3_gas_a (yr)', 'Gasage (AICC2012, yr BP)', 'CO2 (ppmv)', 'sigma (ppmv)']\n",
    "\n",
    "#attempt to clean up numerics by removing spaces\n",
    "#NOTE - new function to do this on the read_csv now used\n",
    "# ref https://stackoverflow.com/questions/13385860/how-can-i-remove-extra-whitespace-from-strings-when-parsing-a-csv-file-in-pandas\n",
    "#This method works but is very slow, taking 10 minutes 50 seconds\n",
    "#table = pd.read_table(save_filename,\n",
    "#                      names=[\"(Depth m)\", \"EDC3_gas_a (yr)\", \"CO2 (ppmv)\", \"sigma (ppmv)\"],\n",
    "#                      converters = {'(Depth m)' : strip,\n",
    "#                                    'EDC3_gas_a (yr)' : strip,\n",
    "#                                    'CO2 (ppmv)' : strip,\n",
    "#                                    'sigma (ppmv)' : strip})\n",
    "\n",
    "# Below code replaced with function\n",
    "#if pd.api.types.is_string_dtype(df[\"(Depth m)\"]):\n",
    "#    numeric_vars['(Depth m)'] = numeric_vars['(Depth m)'].str.strip()\n",
    "#if pd.api.types.is_string_dtype(df[\"EDC3_gas_a (yr)\"]):\n",
    "#    numeric_vars['EDC3_gas_a (yr)'] = numeric_vars['EDC3_gas_a (yr)'].str.strip()\n",
    "#if pd.api.types.is_string_dtype(df[\"CO2 (ppmv)\"]):\n",
    "#    numeric_vars['CO2 (ppmv)'] = numeric_vars['CO2 (ppmv)'].str.strip()\n",
    "#if pd.api.types.is_string_dtype(df[\"sigma (ppmv)\"]):\n",
    "#    numeric_vars['sigma (ppmv)'] = numeric_vars['sigma (ppmv)'].str.strip()\n",
    "\n",
    "#################################\n",
    "# Compare C02 between sources\n",
    "#################################\n",
    "#\n",
    "# plot with seaborn and use the hue parameter\n",
    "# Look at depth of 3000m plus as moesm data for depths are greather than 3000m\n",
    "# and want to compare like for like data from both datasets.\n",
    "# Will use min value for moem dataset as a cutoff and look at anything >= than that value.\n",
    "# Here I utilise min and max values of the moesm depth data.\n",
    "# ref https://stackoverflow.com/questions/35873927/rounding-down-values-in-pandas-dataframe-column-with-nans\n",
    "# ref https://www.geeksforgeeks.org/how-to-convert-float-to-int-in-python/\n",
    "min_moem_depth=moesm31_combined['Depth (m)'].min()\n",
    "max_moem_depth=moesm31_combined['Depth (m)'].max()\n",
    "\n",
    "print('moem_depth_min>',min_moem_depth)\n",
    "print('moem_depth_max>',max_moem_depth)\n",
    "\n",
    "\n",
    "# ref https://sparkbyexamples.com/pandas/pandas-select-dataframe-rows-between-two-dates/\n",
    "# and changed for depth\n",
    "#df_min_max_moem_depth = all_combined.loc[all_combined[\"Depth (m)\"].between(moem_depth_min, moem_depth_max)].copy()\n",
    "df_all_copy=all_combined.copy()\n",
    "df_all_copy.rename(columns={'Depth (m)': 'Depth_m'}, inplace=True)\n",
    "# make sure Depth_m column is numeric\n",
    "#df_all_copy['Depth_m'] = pd.to_numeric(df_all_copy['Depth_m'], errors='coerce')\n",
    "\n",
    "\n",
    "print('df_all_copy.dtypes >>>>>>>>',df_all_copy.dtypes)\n",
    "\n",
    "#df_all_copy = df_all_copy['Depth_m'].gt(moem_depth_min)\n",
    "#df_all_copy = df_all_copy['Depth_m'].lt(moem_depth_max)\n",
    "\n",
    "#cols = ['Depth_m']\n",
    "#df_all_copy[cols] = df_all_copy[df_all_copy[cols] > int(min_moem_depth)][cols]\n",
    "#df_all_copy.dropna()\n",
    "\n",
    "#df_all_copy['Depth_m'] = df_all_copy['Depth_m'].astype(int)\n",
    "df_all_copy = df_all_copy[df_all_copy[\"Depth_m\"].between(min_moem_depth, max_moem_depth)]\n",
    "#df_min_max_moem_depth = df_all_copy.copy()\n",
    "#df_min_max_moem_depth = df_all_copy.query('Depth_m>@moem_depth_min and Depth_m<@moem_depth_max')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='CO2 (ppmv)', y='Depth_m', data=df_all_copy, hue='source file')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title='Comparison of CO2 (ppmv) for Depth (m) between 2 sources.' \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "# Temperate VS C02\n",
    "#################################\n",
    "#\n",
    "print('************************************ Temperate VS C02 *****************************************')\n",
    "df_all_copy=all_combined.copy()\n",
    "df_all_copy= df_all_copy[df_all_copy['Temperature'] != 0]\n",
    "print(df_all_copy.describe())\n",
    "\n",
    "#df_all_copy.rename(columns={'Depth (m)': 'Depth_m'}, inplace=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='CO2 (ppmv)', y='Temperature', data=df_all_copy, hue='source file')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title='Comparison of CO2 (ppmv) VS Temperature.' \n",
    "plt.show()\n",
    "\n",
    "\n",
    "for var_name in numeric_vars:\n",
    "    #kde - If True, compute a kernel density estimate to smooth the distribution and show on the plot as \n",
    "    # (one or more) line(s). Only relevant with univariate data.\n",
    "    # Ref ref https://seaborn.pydata.org/generated/seaborn.histplot.html\n",
    "    #sns.histplot(df[var_name])\n",
    "\n",
    "    print('>>>>>>>>>>>>>>>>>>>>>Plotting for:*',var_name,'*<<<<    >>>>*',all_combined[var_name],'* <<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    print('>>>>>>>>>> DTYPE:[' , all_combined[var_name].dtype, ']<<<<<<<<<<<<<<<<<<<<<<<')\n",
    "    sns.histplot(all_combined[var_name], kde=True)\n",
    "    plt.title(f'Plot for {var_name}')\n",
    "    plt.xlabel(var_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a seaborn plot for each of the string columns\n",
    "# Build a list of the string variables, and then use in a loop.\n",
    "# ref https://seaborn.pydata.org/generated/seaborn.histplot.html\n",
    "string_vars = ['station', 'uni', 'source file']\n",
    "for var_name in string_vars:\n",
    "    #kde - If True, compute a kernel density estimate to smooth the distribution and show on the plot as \n",
    "    # (one or more) line(s). Only relevant with univariate data.\n",
    "    # Ref ref https://seaborn.pydata.org/generated/seaborn.histplot.html\n",
    "    sns.histplot(all_combined[var_name], kde=True)\n",
    "    plt.title(f'Plot for {var_name}')\n",
    "    plt.xlabel(var_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
